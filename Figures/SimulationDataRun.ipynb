{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the whole method on multiple repetitions of simulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "#from DL.knockoff.KnockoffGenerator import KnockoffGenerator;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run MGM to identify linear associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ihome/hpark/zhf16/causalDeepVASE/MGM/tetradLite_likelihood_for_all.jar\n"
     ]
    }
   ],
   "source": [
    "from MGM.MGM import MGM\n",
    "mgm = MGM();\n",
    "\n",
    "def runMGM(n,p,iters):\n",
    "    \n",
    "    dirPath = \"data/simulated_data/nonlinear/\"+str(n)+\"samples/\"+str(p)+\"p/\";\n",
    "    resultPath = \"data/simulated_data/nonlinear/\";\n",
    "\n",
    "    XFileName = \"X_n\"+str(n)+\"_p\"+str(p)+\"_iter\"+str(iterIdx)+\".csv\";\n",
    "    YFileName = \"y_si_n\"+str(n)+\"_p\"+str(p)+\"_iter\"+str(iterIdx)+\".csv\";\n",
    "\n",
    "    XDataDF = pd.read_csv(dirPath+XFileName,sep='\\t');\n",
    "    YDataDF = pd.read_csv(dirPath+YFileName,sep='\\t');\n",
    "    YDataDF = YDataDF.rename(columns={\"V1\": \"Y\"});\n",
    "    dataDF = pd.concat([XDataDF,YDataDF],axis=1);\n",
    "\n",
    "    XYFileName = \"p\"+str(p)+\"_iter\"+str(iterIdx)+\"_XYData.txt\";\n",
    "    dataDFPath = resultPath+XYFileName;\n",
    "    dataDF.to_csv(dataDFPath,index=None, sep=\"\\t\");\n",
    "    \n",
    "    mgm_output_file = mgm.runMGM(resultPath, XYFileName,lambda_continuous_continuous = 0.3, lamda_continuous_discrete = 0.3, lamda_discrete_discrete = 0.3);\n",
    "    print(\"Please find MGM's output file as:\");\n",
    "    mgm_output_file_path = resultPath+os.path.sep+mgm_output_file[0];\n",
    "    print(mgm_output_file_path);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please find MGM's output file as:\n",
      "data/simulated_data/nonlinear//p40_iter5_XYData_MGM_associations.csv\n"
     ]
    }
   ],
   "source": [
    "sampleNumbers = [10000];\n",
    "pNumbers = [40];\n",
    "#iterIdxs = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20];\n",
    "iterIdxs = [5];\n",
    "for sampleNumber in sampleNumbers:\n",
    "    for pNumber in pNumbers:\n",
    "        for iterIdx in iterIdxs:\n",
    "            runMGM(sampleNumber,pNumber,iterIdx);\n",
    "#mgm.showDownJVM();\n",
    "#dataDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the DNN to identify nonlinear associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from DL.knockoff.KnockoffGenerator import KnockoffGenerator;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DL.DNN.DNN import DNN;\n",
    "from DL.FDR.FDR_control import FDR_control;\n",
    "\n",
    "def runProcedure(n,p,iterIdx):\n",
    "    dirPath = \"data/simulated_data/nonlinear/\";\n",
    "    dataDirPath = dirPath+str(n)+\"samples/\"+str(p)+\"p/\";\n",
    "    #result_dir = \"data/simulated_data/nonlinear/\"+str(n)+\"samples/\"+str(p)+\"p/DNN_result/\";\n",
    "    result_dir = dirPath+\"DNN_result/\";\n",
    "    if os.path.exists(result_dir):\n",
    "        shutil.rmtree(result_dir);\n",
    "\n",
    "    XFileName = \"X_n\"+str(n)+\"_p\"+str(p)+\"_iter\"+str(iterIdx)+\".csv\";\n",
    "    YFileName = \"y_si_n\"+str(n)+\"_p\"+str(p)+\"_iter\"+str(iterIdx)+\".csv\";\n",
    "    \n",
    "    generator = KnockoffGenerator();\n",
    "    #knockoff_file_path = generator.DNN_knockoff(dataDirPath, XFileName,YFileName);\n",
    "    #knockoff_file_path = generator.ISEEKnockoff(dataDirPath, XFileName);\n",
    "    knockoff_file_path = generator.CholLuKnockoff(dataDirPath, XFileName);\n",
    "\n",
    "    print(\"The newly generated knockoff file is named as:\")\n",
    "    print(knockoff_file_path);\n",
    "    \n",
    "    # After generating the knockoff data, run DNN\n",
    "    X_knockoff_data = pd.read_csv(knockoff_file_path,sep='\\t');\n",
    "    print(X_knockoff_data.shape);\n",
    "\n",
    "    #Y_data\n",
    "    original_data_Y = pd.read_csv(os.path.join(dataDirPath,YFileName));\n",
    "\n",
    "    X_values = X_knockoff_data.values;\n",
    "    Y_values = original_data_Y.values;\n",
    "    \n",
    "    pNum = int(X_values.shape[1] / 2);\n",
    "    nNum = X_values.shape[0];\n",
    "    print(X_values.shape);\n",
    "    print(Y_values.shape);\n",
    "    print(pNum);\n",
    "    \n",
    "    X_origin = X_values[:, 0:pNum];\n",
    "    X_knockoff = X_values[:, pNum:];\n",
    "\n",
    "    x3D_train = np.zeros((nNum, pNum, 2));\n",
    "    x3D_train[:, :, 0] = X_origin;\n",
    "    x3D_train[:, :, 1] = X_knockoff;\n",
    "    label_train = Y_values;\n",
    "    \n",
    "    coeff = 0.05 * np.sqrt(2.0 * np.log(pNum) / nNum);\n",
    "    n_outputs = original_data_Y.shape[1];\n",
    "\n",
    "    #Save the DNN output to the following directory.\n",
    "\n",
    "    if not os.path.exists(result_dir):\n",
    "        os.makedirs(result_dir);\n",
    "    \n",
    "    dnn = DNN();\n",
    "    model = dnn.build_DNN(pNum, n_outputs, coeff);\n",
    "    callback = DNN.Job_finish_Callback(result_dir,pNum);\n",
    "    dnn.train_DNN(model, x3D_train, label_train,callback);\n",
    "    \n",
    "    #Apply FDR control to DNN result\n",
    "    control = FDR_control();\n",
    "    selected_features = control.controlFilter(dataDirPath +os.path.sep+ XFileName, result_dir, offset=1, q=0.05);\n",
    "    #Save the selected associations\n",
    "    selected_associations = [];\n",
    "    for ele in selected_features:\n",
    "        selected_associations.append({\"Feature1\":ele[0],\"Feature2\":\"Y\",\"Stat\":ele[1]});\n",
    "    pd.DataFrame(selected_associations).to_csv(dirPath+\"DNN_selected_associations_\"+str(p)+\"p_\"+str(iterIdx)+\"iter.csv\")\n",
    "    #Delete knockoff file if exists\n",
    "    if os.path.exists(knockoff_file_path):\n",
    "        os.remove(knockoff_file_path);\n",
    "#temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleNumbers = [10000];\n",
    "pNumbers = [40];\n",
    "iterIdxs = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20];\n",
    "#iterIdxs = [1];\n",
    "for sampleNumber in sampleNumbers:\n",
    "    for pNumber in pNumbers:\n",
    "        for iterIdx in iterIdxs:\n",
    "            runProcedure(sampleNumber,pNumber,iterIdx);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify causal directions for all the identified associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeCycles(causalGraph):\n",
    "    #print(causalGraph.edges());\n",
    "    cycyles = list(nx.simple_cycles(causalGraph));\n",
    "    for cycle in cycyles:\n",
    "        source_node = cycle[0];\n",
    "        target_node_index = 1;\n",
    "    \n",
    "        marked_source_node = \"\";\n",
    "        marked_target_node = \"\";\n",
    "        marked_weight = 0;\n",
    "    \n",
    "        while (target_node_index<len(cycle)):\n",
    "            target_node = cycle[target_node_index];\n",
    "            weight = causalGraph.get_edge_data(source_node,target_node)['weight'];\n",
    "            #print(weight);\n",
    "            if (marked_source_node ==\"\" and marked_target_node==\"\") or marked_weight<weight:\n",
    "                marked_weight = weight;\n",
    "                marked_source_node = source_node;\n",
    "                marked_target_node = target_node;\n",
    "            \n",
    "            source_node = target_node;\n",
    "            target_node_index=target_node_index+1;\n",
    "        target_node = cycle[0];\n",
    "        weight = causalGraph.get_edge_data(source_node,target_node)['weight'];\n",
    "        #print(weight);\n",
    "        if marked_weight<weight:\n",
    "            marked_weight = weight;\n",
    "            marked_source_node = source_node;\n",
    "            marked_target_node = target_node;\n",
    "        #Delete the node with smallest weight\n",
    "        causalGraph.remove_edge(source_node,target_node);\n",
    "    #print(causalGraph.edges());\n",
    "    return causalGraph;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleNumbers = [200,600,1000];\n",
    "pNumbers = [50,200];\n",
    "causalResultDictionary = {};\n",
    "for sampleNumber in sampleNumbers:\n",
    "    for pNumber in pNumbers:\n",
    "        meanAccuracyRate = processResultFile(sampleNumber,pNumber);\n",
    "        if sampleNumber not in causalResultDictionary:\n",
    "            causalResultDictionary[sampleNumber] = {pNumber:meanAccuracyRate};\n",
    "        else:\n",
    "            causalResultDictionary[sampleNumber][pNumber] = meanAccuracyRate;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(causalResultDictionary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env36",
   "language": "python",
   "name": "env36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ihome/hpark/zhf16/causalDeepVASE/MGM/tetradLite.jar\n",
      "Please find MGM's output file as:\n",
      "/ihome/hpark/zhf16/causalDeepVASE/data/200p_1000samples_XY_MGM_associations.csv\n"
     ]
    }
   ],
   "source": [
    "XY_file_name = \"200p_1000samples_XY.txt\";\n",
    "data_folder_path = \"/ihome/hpark/zhf16/causalDeepVASE/data\";\n",
    "'''\n",
    "Run MGM\n",
    "Note: MGM was implemented in Java and the following Python APIs call the Java implementation.\n",
    "Please restart the Python program after encountering a JVM problem.\n",
    "The input data file should be \".txt\" format and should also include the response variables.\n",
    "Here is how the input data should look like:\n",
    "X1 X2 ... Xp Y1 ... Yq\n",
    "1  1  ... 1  1  ... 1\n",
    "'''\n",
    "from MGM.MGM import MGM\n",
    "mgm = MGM();\n",
    "mgm_output_file = mgm.runMGM(data_folder_path, XY_file_name,lambda_continuous_continuous = 0.3, lamda_continuous_discrete = 0.3, lamda_discrete_discrete = 0.3);\n",
    "print(\"Please find MGM's output file as:\");\n",
    "mgm_output_file_path = data_folder_path+os.path.sep+mgm_output_file;\n",
    "print(mgm_output_file_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__\n",
      "(1000, 200)\n",
      "(1000, 1)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               25728     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 36,097\n",
      "Trainable params: 36,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ihome/hpark/zhf16/causalDeepVASE/DL/knockoff/KnockoffGenerator.py:136: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(128, activation=\"relu\", input_dim=200, kernel_initializer=\"glorot_normal\", use_bias=True)`\n",
      "  model.add(Dense(128, activation='relu', bias=True, init='glorot_normal', input_dim=n_features));\n",
      "/ihome/hpark/zhf16/causalDeepVASE/DL/knockoff/KnockoffGenerator.py:137: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(64, activation=\"relu\", kernel_initializer=\"glorot_normal\", use_bias=True)`\n",
      "  model.add(Dense(64, activation='relu', bias=True, init='glorot_normal'));\n",
      "/ihome/hpark/zhf16/causalDeepVASE/DL/knockoff/KnockoffGenerator.py:138: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, activation=\"relu\", kernel_initializer=\"glorot_normal\", use_bias=True)`\n",
      "  model.add(Dense(32, activation='relu', bias=True, init='glorot_normal'));\n",
      "/ihome/hpark/zhf16/causalDeepVASE/DL/knockoff/KnockoffGenerator.py:139: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"glorot_normal\")`\n",
      "  model.add(Dense(n_targets, init='glorot_normal'));\n",
      "/ihome/hpark/zhf16/causalDeepVASE/DL/knockoff/KnockoffGenerator.py:143: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  model.fit(features, output, nb_epoch=50, batch_size=32);\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 1s 555us/step - loss: 29795700.4880\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 29778715.5664\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 29730439.2740\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 29579986.6560\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 28926815.8520\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 27341376.4120\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 24028352.7240\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 20303100.6060\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 17187786.3780\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 14288449.8080\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 13651119.7920\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 12149866.0720\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 11495076.4000\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 10851313.7840\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 10419737.4000\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 9677442.2560\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 9488211.6640\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 9170151.3480\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 9082816.5840\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 8985329.6640\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 8672469.1400\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 8276533.1580\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 7799305.3660\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 8238456.0400\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 7782776.9500\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 7544938.4960\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 7652538.3720\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 7701030.0440\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 7267927.5680\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 6841995.8360\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 6709137.1200\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 7367299.5860\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 6764130.3820\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 6700532.3640\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 6344805.5160\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 6365472.8860\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 6194735.0720\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 6014561.7480\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 6786395.6160\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 6435292.4780\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 6092287.7640\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 5407052.4000\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 5506123.9660\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 5328269.8740\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 5371108.9560\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 5368461.3320\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 5366578.9840\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 5156524.2050\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 4953811.2840\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 4949025.1410\n",
      "nonlinear_mxts_mode is set to: DeepLIFT_GenomicsDefault\n",
      "For layer 0 the preceding linear layer is preact_0 of type Dense;\n",
      "In accordance with nonlinear_mxts_modeDeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to RevealCancel\n",
      "For layer 1 the preceding linear layer is preact_1 of type Dense;\n",
      "In accordance with nonlinear_mxts_modeDeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to RevealCancel\n",
      "For layer 2 the preceding linear layer is preact_2 of type Dense;\n",
      "In accordance with nonlinear_mxts_modeDeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to RevealCancel\n",
      "No reference provided - using zeros\n",
      "['K1', 'K2', 'K3', 'K4', 'K5', 'K6', 'K7', 'K8', 'K9', 'K10', 'K11', 'K12', 'K13', 'K14', 'K15', 'K16', 'K17', 'K18', 'K19', 'K20', 'K21', 'K22', 'K23', 'K24', 'K25', 'K26', 'K27', 'K28', 'K29', 'K30', 'K31', 'K32', 'K33', 'K34', 'K35', 'K36', 'K37', 'K38', 'K39', 'K40', 'K41', 'K42', 'K43', 'K44', 'K45', 'K46', 'K47', 'K48', 'K49', 'K50', 'K51', 'K52', 'K53', 'K54', 'K55', 'K56', 'K57', 'K58', 'K59', 'K60', 'K61', 'K62', 'K63', 'K64', 'K65', 'K66', 'K67', 'K68', 'K69', 'K70', 'K71', 'K72', 'K73', 'K74', 'K75', 'K76', 'K77', 'K78', 'K79', 'K80', 'K81', 'K82', 'K83', 'K84', 'K85', 'K86', 'K87', 'K88', 'K89', 'K90', 'K91', 'K92', 'K93', 'K94', 'K95', 'K96', 'K97', 'K98', 'K99', 'K100', 'K101', 'K102', 'K103', 'K104', 'K105', 'K106', 'K107', 'K108', 'K109', 'K110', 'K111', 'K112', 'K113', 'K114', 'K115', 'K116', 'K117', 'K118', 'K119', 'K120', 'K121', 'K122', 'K123', 'K124', 'K125', 'K126', 'K127', 'K128', 'K129', 'K130', 'K131', 'K132', 'K133', 'K134', 'K135', 'K136', 'K137', 'K138', 'K139', 'K140', 'K141', 'K142', 'K143', 'K144', 'K145', 'K146', 'K147', 'K148', 'K149', 'K150', 'K151', 'K152', 'K153', 'K154', 'K155', 'K156', 'K157', 'K158', 'K159', 'K160', 'K161', 'K162', 'K163', 'K164', 'K165', 'K166', 'K167', 'K168', 'K169', 'K170', 'K171', 'K172', 'K173', 'K174', 'K175', 'K176', 'K177', 'K178', 'K179', 'K180', 'K181', 'K182', 'K183', 'K184', 'K185', 'K186', 'K187', 'K188', 'K189', 'K190', 'K191', 'K192', 'K193', 'K194', 'K195', 'K196', 'K197', 'K198', 'K199', 'K200']\n",
      "The newly generated knockoff file is named as:\n",
      "/ihome/hpark/zhf16/causalDeepVASE/data/200p_1000samples_X_DNN_knockoff.csv\n"
     ]
    }
   ],
   "source": [
    "X_file_name = \"200p_1000samples_X.csv\";\n",
    "'''\n",
    "#Generate knockoff data using one of three methods: ISEE Omega, DNN, and Cholesky_LU.\n",
    "#Recommended: ISEE Omega or Cholesky_LU.\n",
    "The code for generating ISEE Omega knockoff is implemented using R. Please make sure your computer has R installed.\n",
    "'''\n",
    "from DL.knockoff.KnockoffGenerator import KnockoffGenerator;\n",
    "generator = KnockoffGenerator();\n",
    "\n",
    "# knockoff_file_path = generator.Chol_Lu_knockoff(data_folder_path, X_file_name);\n",
    "\n",
    "# #If want to generate ISEE Omega knockoff, please set the ISEE code path and R home environment.\n",
    "# generator.set_ISEE_path(\"/ihome/hpark/zhf16/causalDeepVASE/\");\n",
    "# generator.set_R_home('/ihome/hpark/zhf16/.conda/envs/env36/lib/R');\n",
    "# knockoff_file_path = generator.ISEE_knockoff(data_folder_path, X_file_name);\n",
    "\n",
    "Y_file_name = '200p_1000samples_Y.csv';\n",
    "knockoff_file_path = generator.DNN_knockoff(data_folder_path, X_file_name,Y_file_name);\n",
    "\n",
    "print(\"The newly generated knockoff file is named as:\")\n",
    "print(knockoff_file_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 400)\n",
      "(1000, 400)\n",
      "(1000, 1)\n",
      "200\n",
      "__init__parameters\n",
      "[layer]: Input\t[shape]: [None, 200, 2] \n",
      "\n",
      "[layer]: LocallyConnected1D\t[shape]: [None, 200, 1] \n",
      "\n",
      "[layer]: LocallyConnected1D\t[shape]: [None, 200, 1] \n",
      "\n",
      "[layer]: Flatten\t[shape]: [None, None] \n",
      "\n",
      "[layer]: Dense\t[shape]: [None, 200] \n",
      "\n",
      "[layer]: Dense\t[shape]: [None, 200] \n",
      "\n",
      "[layer]: Dense\t[shape]: [None, 1] \n",
      "\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 29794096.5175\n",
      "on_epoch_end\n",
      "h_local1_weight = (200, 2, 1)\n",
      "h_local2_weight = (200, 1, 1)\n",
      "h0 = (200, 2)\n",
      "h0_abs = (200, 2)\n",
      "h1 = (200, 200)\n",
      "h2 = (200, 200)\n",
      "h3 = (200, 1)\n",
      "W1 = (200, 200)\n",
      "W2 = (200, 200)\n",
      "W3 = (200, 1)\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 1s 541us/step - loss: 29789754.6150\n",
      "on_epoch_end\n",
      "h_local1_weight = (200, 2, 1)\n",
      "h_local2_weight = (200, 1, 1)\n",
      "h0 = (200, 2)\n",
      "h0_abs = (200, 2)\n",
      "h1 = (200, 200)\n",
      "h2 = (200, 200)\n",
      "h3 = (200, 1)\n",
      "W1 = (200, 200)\n",
      "W2 = (200, 200)\n",
      "W3 = (200, 1)\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 29709190.7200\n",
      "on_epoch_end\n",
      "h_local1_weight = (200, 2, 1)\n",
      "h_local2_weight = (200, 1, 1)\n",
      "h0 = (200, 2)\n",
      "h0_abs = (200, 2)\n",
      "h1 = (200, 200)\n",
      "h2 = (200, 200)\n",
      "h3 = (200, 1)\n",
      "W1 = (200, 200)\n",
      "W2 = (200, 200)\n",
      "W3 = (200, 1)\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 29036605.2950\n",
      "on_epoch_end\n",
      "h_local1_weight = (200, 2, 1)\n",
      "h_local2_weight = (200, 1, 1)\n",
      "h0 = (200, 2)\n",
      "h0_abs = (200, 2)\n",
      "h1 = (200, 200)\n",
      "h2 = (200, 200)\n",
      "h3 = (200, 1)\n",
      "W1 = (200, 200)\n",
      "W2 = (200, 200)\n",
      "W3 = (200, 1)\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 1s 510us/step - loss: 26296264.3922\n",
      "on_epoch_end\n",
      "h_local1_weight = (200, 2, 1)\n",
      "h_local2_weight = (200, 1, 1)\n",
      "h0 = (200, 2)\n",
      "h0_abs = (200, 2)\n",
      "h1 = (200, 200)\n",
      "h2 = (200, 200)\n",
      "h3 = (200, 1)\n",
      "W1 = (200, 200)\n",
      "W2 = (200, 200)\n",
      "W3 = (200, 1)\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 20806429.2175\n",
      "on_epoch_end\n",
      "h_local1_weight = (200, 2, 1)\n",
      "h_local2_weight = (200, 1, 1)\n",
      "h0 = (200, 2)\n",
      "h0_abs = (200, 2)\n",
      "h1 = (200, 200)\n",
      "h2 = (200, 200)\n",
      "h3 = (200, 1)\n",
      "W1 = (200, 200)\n",
      "W2 = (200, 200)\n",
      "W3 = (200, 1)\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 1s 538us/step - loss: 15132483.3587\n",
      "on_epoch_end\n",
      "h_local1_weight = (200, 2, 1)\n",
      "h_local2_weight = (200, 1, 1)\n",
      "h0 = (200, 2)\n",
      "h0_abs = (200, 2)\n",
      "h1 = (200, 200)\n",
      "h2 = (200, 200)\n",
      "h3 = (200, 1)\n",
      "W1 = (200, 200)\n",
      "W2 = (200, 200)\n",
      "W3 = (200, 1)\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 12741404.0488\n",
      "on_epoch_end\n",
      "h_local1_weight = (200, 2, 1)\n",
      "h_local2_weight = (200, 1, 1)\n",
      "h0 = (200, 2)\n",
      "h0_abs = (200, 2)\n",
      "h1 = (200, 200)\n",
      "h2 = (200, 200)\n",
      "h3 = (200, 1)\n",
      "W1 = (200, 200)\n",
      "W2 = (200, 200)\n",
      "W3 = (200, 1)\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 11690165.7700\n",
      "on_epoch_end\n",
      "h_local1_weight = (200, 2, 1)\n",
      "h_local2_weight = (200, 1, 1)\n",
      "h0 = (200, 2)\n",
      "h0_abs = (200, 2)\n",
      "h1 = (200, 200)\n",
      "h2 = (200, 200)\n",
      "h3 = (200, 1)\n",
      "W1 = (200, 200)\n",
      "W2 = (200, 200)\n",
      "W3 = (200, 1)\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 11363429.0675\n",
      "on_epoch_end\n",
      "h_local1_weight = (200, 2, 1)\n",
      "h_local2_weight = (200, 1, 1)\n",
      "h0 = (200, 2)\n",
      "h0_abs = (200, 2)\n",
      "h1 = (200, 200)\n",
      "h2 = (200, 200)\n",
      "h3 = (200, 1)\n",
      "W1 = (200, 200)\n",
      "W2 = (200, 200)\n",
      "W3 = (200, 1)\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 11233020.1200\n",
      "on_epoch_end\n",
      "h_local1_weight = (200, 2, 1)\n",
      "h_local2_weight = (200, 1, 1)\n",
      "h0 = (200, 2)\n",
      "h0_abs = (200, 2)\n",
      "h1 = (200, 200)\n",
      "h2 = (200, 200)\n",
      "h3 = (200, 1)\n",
      "W1 = (200, 200)\n",
      "W2 = (200, 200)\n",
      "W3 = (200, 1)\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 10941609.3900\n",
      "on_epoch_end\n",
      "h_local1_weight = (200, 2, 1)\n",
      "h_local2_weight = (200, 1, 1)\n",
      "h0 = (200, 2)\n",
      "h0_abs = (200, 2)\n",
      "h1 = (200, 200)\n",
      "h2 = (200, 200)\n",
      "h3 = (200, 1)\n",
      "W1 = (200, 200)\n",
      "W2 = (200, 200)\n",
      "W3 = (200, 1)\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 1s 572us/step - loss: 10865965.3350\n",
      "on_epoch_end\n",
      "h_local1_weight = (200, 2, 1)\n",
      "h_local2_weight = (200, 1, 1)\n",
      "h0 = (200, 2)\n",
      "h0_abs = (200, 2)\n",
      "h1 = (200, 200)\n",
      "h2 = (200, 200)\n",
      "h3 = (200, 1)\n",
      "W1 = (200, 200)\n",
      "W2 = (200, 200)\n",
      "W3 = (200, 1)\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 10722316.2975\n",
      "on_epoch_end\n",
      "h_local1_weight = (200, 2, 1)\n",
      "h_local2_weight = (200, 1, 1)\n",
      "h0 = (200, 2)\n",
      "h0_abs = (200, 2)\n",
      "h1 = (200, 200)\n",
      "h2 = (200, 200)\n",
      "h3 = (200, 1)\n",
      "W1 = (200, 200)\n",
      "W2 = (200, 200)\n",
      "W3 = (200, 1)\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 1s 560us/step - loss: 10643806.1625\n",
      "on_epoch_end\n",
      "h_local1_weight = (200, 2, 1)\n",
      "h_local2_weight = (200, 1, 1)\n",
      "h0 = (200, 2)\n",
      "h0_abs = (200, 2)\n",
      "h1 = (200, 200)\n",
      "h2 = (200, 200)\n",
      "h3 = (200, 1)\n",
      "W1 = (200, 200)\n",
      "W2 = (200, 200)\n",
      "W3 = (200, 1)\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 1s 581us/step - loss: 10625221.2375\n",
      "on_epoch_end\n",
      "h_local1_weight = (200, 2, 1)\n",
      "h_local2_weight = (200, 1, 1)\n",
      "h0 = (200, 2)\n",
      "h0_abs = (200, 2)\n",
      "h1 = (200, 200)\n",
      "h2 = (200, 200)\n",
      "h3 = (200, 1)\n",
      "W1 = (200, 200)\n",
      "W2 = (200, 200)\n",
      "W3 = (200, 1)\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 1s 562us/step - loss: 10519609.9075\n",
      "on_epoch_end\n",
      "h_local1_weight = (200, 2, 1)\n",
      "h_local2_weight = (200, 1, 1)\n",
      "h0 = (200, 2)\n",
      "h0_abs = (200, 2)\n",
      "h1 = (200, 200)\n",
      "h2 = (200, 200)\n",
      "h3 = (200, 1)\n",
      "W1 = (200, 200)\n",
      "W2 = (200, 200)\n",
      "W3 = (200, 1)\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 10558836.5875\n",
      "on_epoch_end\n",
      "h_local1_weight = (200, 2, 1)\n",
      "h_local2_weight = (200, 1, 1)\n",
      "h0 = (200, 2)\n",
      "h0_abs = (200, 2)\n",
      "h1 = (200, 200)\n",
      "h2 = (200, 200)\n",
      "h3 = (200, 1)\n",
      "W1 = (200, 200)\n",
      "W2 = (200, 200)\n",
      "W3 = (200, 1)\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 1s 555us/step - loss: 10604718.3050\n",
      "on_epoch_end\n",
      "h_local1_weight = (200, 2, 1)\n",
      "h_local2_weight = (200, 1, 1)\n",
      "h0 = (200, 2)\n",
      "h0_abs = (200, 2)\n",
      "h1 = (200, 200)\n",
      "h2 = (200, 200)\n",
      "h3 = (200, 1)\n",
      "W1 = (200, 200)\n",
      "W2 = (200, 200)\n",
      "W3 = (200, 1)\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 10373716.7600\n",
      "on_epoch_end\n",
      "h_local1_weight = (200, 2, 1)\n",
      "h_local2_weight = (200, 1, 1)\n",
      "h0 = (200, 2)\n",
      "h0_abs = (200, 2)\n",
      "h1 = (200, 200)\n",
      "h2 = (200, 200)\n",
      "h3 = (200, 1)\n",
      "W1 = (200, 200)\n",
      "W2 = (200, 200)\n",
      "W3 = (200, 1)\n"
     ]
    }
   ],
   "source": [
    "''''''\n",
    "# After generating the knockoff data, run DNN\n",
    "Y_file_name = '200p_1000samples_Y.csv';\n",
    "X_knockoff_data = pd.read_csv(knockoff_file_path);\n",
    "print(X_knockoff_data.shape)\n",
    "# X_knockoff_data\n",
    "\n",
    "#nutrient_data\n",
    "original_data_Y = pd.read_csv(data_folder_path+os.path.sep+Y_file_name);\n",
    "# original_data_Y\n",
    "\n",
    "X_values = X_knockoff_data.values;\n",
    "Y_values = original_data_Y.values;\n",
    "    \n",
    "p_num = int(X_values.shape[1] / 2);\n",
    "n = X_values.shape[0];\n",
    "print(X_values.shape);\n",
    "print(Y_values.shape);\n",
    "print(p_num);\n",
    "    \n",
    "X_origin = X_values[:, 0:p_num];\n",
    "X_knockoff = X_values[:, p_num:];\n",
    "\n",
    "x3D_train = np.zeros((n, p_num, 2));\n",
    "x3D_train[:, :, 0] = X_origin;\n",
    "x3D_train[:, :, 1] = X_knockoff;\n",
    "label_train = Y_values;\n",
    "    \n",
    "coeff = 0.05 * np.sqrt(2.0 * np.log(p_num) / n);\n",
    "\n",
    "n_outputs = original_data_Y.shape[1];\n",
    "\n",
    "#Save the DNN output to the following directory.\n",
    "result_dir = 'data/DNN_result/';\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir);\n",
    "    \n",
    "from DL.DNN.DNN import DNN;\n",
    "dnn = DNN();\n",
    "model = dnn.build_DNN(p_num, n_outputs, coeff);\n",
    "callback = DNN.Job_finish_Callback(result_dir,p_num);\n",
    "dnn.train_DNN(model, x3D_train, label_train,callback);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "#Apply FDR control to DNN result\n",
    "from DL.FDR.FDR_control import FDR_control;\n",
    "control = FDR_control();\n",
    "selected_features = control.controlFilter(data_folder_path +os.path.sep+ X_file_name, \"/ihome/hpark/zhf16/causalDeepVASE/data/DNN_result\", offset=1, q=0.05);\n",
    "#Save the selected associations\n",
    "selected_associations = [];\n",
    "for ele in selected_features:\n",
    "    selected_associations.append({\"Feature1\":ele,\"Feature2\":\"Y\"});\n",
    "pd.DataFrame(selected_associations).to_csv(\"data/DNN_selected_associations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run DG\n",
    "#Load data\n",
    "X_data = pd.read_csv(\"X_n1000_p50_rep20.csv\");\n",
    "# X_data\n",
    "Y_data = pd.read_csv('y_si_n1000_p50_rep20.csv');\n",
    "#Merge X and Y\n",
    "dataset = pd.concat([X_data, Y_data], axis=1, join='inner');\n",
    "print(dataset.shape);\n",
    "\n",
    "#Calculate the covariance matrix\n",
    "cov_mat = dataset.cov();\n",
    "corr_inv = np.linalg.inv(cov_mat)\n",
    "corr_inv = pd.DataFrame(data=corr_inv, index=cov_mat.index,columns=cov_mat.columns)\n",
    "# corr_inv.head(2)\n",
    "\n",
    "#Convert the columns to their numerical representations\n",
    "col_map = {};\n",
    "col_map_rev = {};\n",
    "col_list = dataset.columns.to_list();\n",
    "for index,ele in enumerate(col_list):\n",
    "    col_map[ele] = index;\n",
    "    col_map_rev[index] = ele;\n",
    "print(dataset.shape);\n",
    "\n",
    "#https://stats.stackexchange.com/questions/13810/threshold-for-correlation-coefficient-to-indicate-statistical-significance-of-a\n",
    "# t = dataset.shape[0]**(1/2)\n",
    "\n",
    "#The data may need to be normalized if neccessary.\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler();\n",
    "# scaled_values = scaler.fit_transform(dataset);\n",
    "# dataset.loc[:,:] = scaled_values;\n",
    "\n",
    "#Initialize DG object\n",
    "from causal.DegenerateGaussianScore import DegenerateGaussianScore\n",
    "dg = DegenerateGaussianScore(dataset,discrete_threshold=0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_associations_sum = [];\n",
    "#Load both MGM-identified and DNN associations\n",
    "MGM_associations = pd.read_csv(\"X_n1000_p50_rep20_MGM_associations.csv\");\n",
    "for index,row in MGM_associations.iterrows():\n",
    "    if row[\"Feature1\"]==\"Y\" or row[\"Feature2\"]==\"Y\":\n",
    "        print(\"Found.\");\n",
    "        selected_associations_sum.append({\"Feature1\":row[\"Feature1\"],\"Feature2\":row[\"Feature2\"]});\n",
    "        \n",
    "DNN_associations = pd.read_csv(\"DNN_selected_associations.csv\");\n",
    "for index,row in DNN_associations.iterrows():\n",
    "    selected_associations_sum.append({\"Feature1\":row[\"Feature1\"],\"Feature2\":row[\"Feature2\"]});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ele in selected_associations_sum:\n",
    "    f1 = ele[\"Feature1\"];\n",
    "    f2 = ele[\"Feature2\"];\n",
    "    \n",
    "    inv_val = abs(corr_inv[f1][f2]);\n",
    "    if inv_val<0.0:\n",
    "        continue;\n",
    "    \n",
    "    n1_idx = col_map[f1];\n",
    "    n2_idx = col_map[f2];\n",
    "    \n",
    "    s1 = dg.localScore(n1_idx,{n2_idx});\n",
    "    s2 = dg.localScore(n2_idx,{n1_idx});\n",
    "    \n",
    "    if s1<s2:\n",
    "        print(\"Cause: \"+f2+\", Effect: \"+f1);\n",
    "    elif s1>s2:\n",
    "        print(\"Cause: \"+f1+\", Effect: \"+f2);\n",
    "    else:\n",
    "        print(\"Same score.\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env36",
   "language": "python",
   "name": "env36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
